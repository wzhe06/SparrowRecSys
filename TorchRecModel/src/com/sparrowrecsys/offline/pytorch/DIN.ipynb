{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get training and test sample, remove unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/home/leon/Documents/SparrowRecSys/src/main/resources/webroot/sampledata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = folder_path + \"/Pytorch_data/trainingSamples.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = folder_path + \"/Pytorch_data/testSamples.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv(training_path, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_path, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "      <th>releaseYear</th>\n",
       "      <th>movieGenre1</th>\n",
       "      <th>movieGenre2</th>\n",
       "      <th>movieGenre3</th>\n",
       "      <th>movieRatingCount</th>\n",
       "      <th>...</th>\n",
       "      <th>userGenre3</th>\n",
       "      <th>userGenre4</th>\n",
       "      <th>userGenre5</th>\n",
       "      <th>scaledReleaseYear</th>\n",
       "      <th>scaledmovieRatingCount</th>\n",
       "      <th>scaledmovieAvgRating</th>\n",
       "      <th>scaledmovieRatingStddev</th>\n",
       "      <th>scaleduserRatingCount</th>\n",
       "      <th>scaleduserAvgRating</th>\n",
       "      <th>scaleduserRatingStddev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>593</td>\n",
       "      <td>10096</td>\n",
       "      <td>4.0</td>\n",
       "      <td>954365552</td>\n",
       "      <td>1</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>13692.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.936777</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.449735</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.279874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>832</td>\n",
       "      <td>10351</td>\n",
       "      <td>3.0</td>\n",
       "      <td>851791379</td>\n",
       "      <td>0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3052.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0.985916</td>\n",
       "      <td>0.208758</td>\n",
       "      <td>0.649306</td>\n",
       "      <td>0.486773</td>\n",
       "      <td>0.112245</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.229560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>10351</td>\n",
       "      <td>3.0</td>\n",
       "      <td>851791395</td>\n",
       "      <td>0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.040438</td>\n",
       "      <td>0.690972</td>\n",
       "      <td>0.502645</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.713333</td>\n",
       "      <td>0.229560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>588</td>\n",
       "      <td>10351</td>\n",
       "      <td>5.0</td>\n",
       "      <td>851792205</td>\n",
       "      <td>1</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>8980.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.614369</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.486773</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0.675555</td>\n",
       "      <td>0.207547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>370</td>\n",
       "      <td>1090</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1117852491</td>\n",
       "      <td>0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3087.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.957747</td>\n",
       "      <td>0.211153</td>\n",
       "      <td>0.482639</td>\n",
       "      <td>0.555555</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.204403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  userId  rating   timestamp  label  releaseYear  movieGenre1  \\\n",
       "0      593   10096     4.0   954365552      1       1991.0           13   \n",
       "1      832   10351     3.0   851791379      0       1996.0           13   \n",
       "2       85   10351     3.0   851791395      0       1995.0           11   \n",
       "3      588   10351     5.0   851792205      1       1992.0            3   \n",
       "4      370    1090     2.0  1117852491      0       1994.0            2   \n",
       "\n",
       "   movieGenre2  movieGenre3  movieRatingCount  ...  userGenre3  userGenre4  \\\n",
       "0            4           12           13692.0  ...          17          12   \n",
       "1           12            0            3052.0  ...           5          12   \n",
       "2            5            0             592.0  ...           5          12   \n",
       "3           15           18            8980.0  ...          12           5   \n",
       "4            7            0            3087.0  ...           0           0   \n",
       "\n",
       "   userGenre5  scaledReleaseYear  scaledmovieRatingCount  \\\n",
       "0           0           0.915493                0.936777   \n",
       "1          13           0.985916                0.208758   \n",
       "2          13           0.971831                0.040438   \n",
       "3          13           0.929577                0.614369   \n",
       "4           0           0.957747                0.211153   \n",
       "\n",
       "   scaledmovieAvgRating  scaledmovieRatingStddev  scaleduserRatingCount  \\\n",
       "0              0.906250                 0.449735               0.030612   \n",
       "1              0.649306                 0.486773               0.112245   \n",
       "2              0.690972                 0.502645               0.122449   \n",
       "3              0.729167                 0.486773               0.224490   \n",
       "4              0.482639                 0.555555               0.030612   \n",
       "\n",
       "   scaleduserAvgRating  scaleduserRatingStddev  \n",
       "0             0.688889                0.279874  \n",
       "1             0.726667                0.229560  \n",
       "2             0.713333                0.229560  \n",
       "3             0.675555                0.207547  \n",
       "4             0.200000                0.204403  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaN items in 'userRatedMovie1' column, movieId starts from 1, so we can use 0 to do padding\n",
    "training_df.fillna(0, inplace=True)\n",
    "test_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns2Keep = ['userId', \n",
    "                'userGenre1', \n",
    "                'scaleduserRatingCount',\n",
    "                'scaleduserAvgRating', \n",
    "                'scaleduserRatingStddev',\n",
    "                'userRatedMovie1',\n",
    "                'userRatedMovie2',\n",
    "                'userRatedMovie3',\n",
    "                'userRatedMovie4',\n",
    "                'userRatedMovie5',\n",
    "                'movieId',  \n",
    "                'movieGenre1', \n",
    "                'scaledReleaseYear',\n",
    "                'scaledmovieRatingCount',\n",
    "                'scaledmovieAvgRating',\n",
    "                'scaledmovieRatingStddev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_feature = training_df[columns2Keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_label = training_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature = test_df[columns2Keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>userGenre1</th>\n",
       "      <th>scaleduserRatingCount</th>\n",
       "      <th>scaleduserAvgRating</th>\n",
       "      <th>scaleduserRatingStddev</th>\n",
       "      <th>userRatedMovie1</th>\n",
       "      <th>userRatedMovie2</th>\n",
       "      <th>userRatedMovie3</th>\n",
       "      <th>userRatedMovie4</th>\n",
       "      <th>userRatedMovie5</th>\n",
       "      <th>movieId</th>\n",
       "      <th>movieGenre1</th>\n",
       "      <th>scaledReleaseYear</th>\n",
       "      <th>scaledmovieRatingCount</th>\n",
       "      <th>scaledmovieAvgRating</th>\n",
       "      <th>scaledmovieRatingStddev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10436</td>\n",
       "      <td>3</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>356.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>588</td>\n",
       "      <td>3</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.614369</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.486773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10436</td>\n",
       "      <td>7</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.828889</td>\n",
       "      <td>0.141509</td>\n",
       "      <td>104.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>586.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>368</td>\n",
       "      <td>3</td>\n",
       "      <td>0.957747</td>\n",
       "      <td>0.256928</td>\n",
       "      <td>0.631945</td>\n",
       "      <td>0.470899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11078</td>\n",
       "      <td>7</td>\n",
       "      <td>0.112245</td>\n",
       "      <td>0.684444</td>\n",
       "      <td>0.229560</td>\n",
       "      <td>608.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.699282</td>\n",
       "      <td>0.965278</td>\n",
       "      <td>0.396825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11078</td>\n",
       "      <td>12</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>0.686667</td>\n",
       "      <td>0.201258</td>\n",
       "      <td>922.0</td>\n",
       "      <td>628.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>527</td>\n",
       "      <td>11</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.753746</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.439153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11078</td>\n",
       "      <td>12</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.686667</td>\n",
       "      <td>0.188679</td>\n",
       "      <td>377.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>733</td>\n",
       "      <td>2</td>\n",
       "      <td>0.985916</td>\n",
       "      <td>0.467739</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.486773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26603</th>\n",
       "      <td>7447</td>\n",
       "      <td>2</td>\n",
       "      <td>0.091837</td>\n",
       "      <td>0.697778</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>780</td>\n",
       "      <td>2</td>\n",
       "      <td>0.985916</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.560847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26604</th>\n",
       "      <td>8700</td>\n",
       "      <td>11</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.198113</td>\n",
       "      <td>589.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>858.0</td>\n",
       "      <td>356</td>\n",
       "      <td>7</td>\n",
       "      <td>0.957747</td>\n",
       "      <td>0.987000</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.502645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26605</th>\n",
       "      <td>8700</td>\n",
       "      <td>11</td>\n",
       "      <td>0.091837</td>\n",
       "      <td>0.717778</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>296.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>593</td>\n",
       "      <td>13</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.936777</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.449735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26606</th>\n",
       "      <td>8700</td>\n",
       "      <td>11</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.220126</td>\n",
       "      <td>110.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>527</td>\n",
       "      <td>11</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.753746</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.439153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26607</th>\n",
       "      <td>9592</td>\n",
       "      <td>7</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>0.764444</td>\n",
       "      <td>0.185535</td>\n",
       "      <td>168.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>902.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.057475</td>\n",
       "      <td>0.378472</td>\n",
       "      <td>0.608466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26608 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  userGenre1  scaleduserRatingCount  scaleduserAvgRating  \\\n",
       "0       10436           3               0.102041             0.888889   \n",
       "1       10436           7               0.244898             0.828889   \n",
       "2       11078           7               0.112245             0.684444   \n",
       "3       11078          12               0.153061             0.686667   \n",
       "4       11078          12               0.214286             0.686667   \n",
       "...       ...         ...                    ...                  ...   \n",
       "26603    7447           2               0.091837             0.697778   \n",
       "26604    8700          11               0.071429             0.680000   \n",
       "26605    8700          11               0.091837             0.717778   \n",
       "26606    8700          11               0.122449             0.722222   \n",
       "26607    9592           7               0.163265             0.764444   \n",
       "\n",
       "       scaleduserRatingStddev  userRatedMovie1  userRatedMovie2  \\\n",
       "0                    0.094340            356.0            593.0   \n",
       "1                    0.141509            104.0            750.0   \n",
       "2                    0.229560            608.0              1.0   \n",
       "3                    0.201258            922.0            628.0   \n",
       "4                    0.188679            377.0            588.0   \n",
       "...                       ...              ...              ...   \n",
       "26603                0.264151              1.0            589.0   \n",
       "26604                0.198113            589.0            750.0   \n",
       "26605                0.226415            296.0            356.0   \n",
       "26606                0.220126            110.0            593.0   \n",
       "26607                0.185535            168.0            500.0   \n",
       "\n",
       "       userRatedMovie3  userRatedMovie4  userRatedMovie5  movieId  \\\n",
       "0                592.0            480.0            899.0      588   \n",
       "1                  2.0            586.0            141.0      368   \n",
       "2                150.0            457.0            593.0       50   \n",
       "3                 47.0             50.0            608.0      527   \n",
       "4                380.0            527.0            922.0      733   \n",
       "...                ...              ...              ...      ...   \n",
       "26603            260.0            110.0            593.0      780   \n",
       "26604            111.0            912.0            858.0      356   \n",
       "26605            589.0            750.0            111.0      593   \n",
       "26606            296.0            356.0            589.0      527   \n",
       "26607             39.0            902.0            231.0       12   \n",
       "\n",
       "       movieGenre1  scaledReleaseYear  scaledmovieRatingCount  \\\n",
       "0                3           0.929577                0.614369   \n",
       "1                3           0.957747                0.256928   \n",
       "2               13           0.971831                0.699282   \n",
       "3               11           0.943662                0.753746   \n",
       "4                2           0.985916                0.467739   \n",
       "...            ...                ...                     ...   \n",
       "26603            2           0.985916                0.702703   \n",
       "26604            7           0.957747                0.987000   \n",
       "26605           13           0.915493                0.936777   \n",
       "26606           11           0.943662                0.753746   \n",
       "26607            7           0.971831                0.057475   \n",
       "\n",
       "       scaledmovieAvgRating  scaledmovieRatingStddev  \n",
       "0                  0.729167                 0.486773  \n",
       "1                  0.631945                 0.470899  \n",
       "2                  0.965278                 0.396825  \n",
       "3                  0.947917                 0.439153  \n",
       "4                  0.722222                 0.486773  \n",
       "...                     ...                      ...  \n",
       "26603              0.625000                 0.560847  \n",
       "26604              0.854167                 0.502645  \n",
       "26605              0.906250                 0.449735  \n",
       "26606              0.947917                 0.439153  \n",
       "26607              0.378472                 0.608466  \n",
       "\n",
       "[26608 rows x 16 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6): # convert userRatedMovie columns to longtype\n",
    "    column_name = \"userRatedMovie\" + str(i)\n",
    "    training_feature[column_name] = training_feature[column_name].astype('int64')\n",
    "    test_feature[column_name] = test_feature[column_name].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>userGenre1</th>\n",
       "      <th>scaleduserRatingCount</th>\n",
       "      <th>scaleduserAvgRating</th>\n",
       "      <th>scaleduserRatingStddev</th>\n",
       "      <th>userRatedMovie1</th>\n",
       "      <th>userRatedMovie2</th>\n",
       "      <th>userRatedMovie3</th>\n",
       "      <th>userRatedMovie4</th>\n",
       "      <th>userRatedMovie5</th>\n",
       "      <th>movieId</th>\n",
       "      <th>movieGenre1</th>\n",
       "      <th>scaledReleaseYear</th>\n",
       "      <th>scaledmovieRatingCount</th>\n",
       "      <th>scaledmovieAvgRating</th>\n",
       "      <th>scaledmovieRatingStddev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10436</td>\n",
       "      <td>3</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>356</td>\n",
       "      <td>593</td>\n",
       "      <td>592</td>\n",
       "      <td>480</td>\n",
       "      <td>899</td>\n",
       "      <td>588</td>\n",
       "      <td>3</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.614369</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.486773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10436</td>\n",
       "      <td>7</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.828889</td>\n",
       "      <td>0.141509</td>\n",
       "      <td>104</td>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>586</td>\n",
       "      <td>141</td>\n",
       "      <td>368</td>\n",
       "      <td>3</td>\n",
       "      <td>0.957747</td>\n",
       "      <td>0.256928</td>\n",
       "      <td>0.631945</td>\n",
       "      <td>0.470899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11078</td>\n",
       "      <td>7</td>\n",
       "      <td>0.112245</td>\n",
       "      <td>0.684444</td>\n",
       "      <td>0.229560</td>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>457</td>\n",
       "      <td>593</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.699282</td>\n",
       "      <td>0.965278</td>\n",
       "      <td>0.396825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11078</td>\n",
       "      <td>12</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>0.686667</td>\n",
       "      <td>0.201258</td>\n",
       "      <td>922</td>\n",
       "      <td>628</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "      <td>608</td>\n",
       "      <td>527</td>\n",
       "      <td>11</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.753746</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.439153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11078</td>\n",
       "      <td>12</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.686667</td>\n",
       "      <td>0.188679</td>\n",
       "      <td>377</td>\n",
       "      <td>588</td>\n",
       "      <td>380</td>\n",
       "      <td>527</td>\n",
       "      <td>922</td>\n",
       "      <td>733</td>\n",
       "      <td>2</td>\n",
       "      <td>0.985916</td>\n",
       "      <td>0.467739</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.486773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26603</th>\n",
       "      <td>7447</td>\n",
       "      <td>2</td>\n",
       "      <td>0.091837</td>\n",
       "      <td>0.697778</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>1</td>\n",
       "      <td>589</td>\n",
       "      <td>260</td>\n",
       "      <td>110</td>\n",
       "      <td>593</td>\n",
       "      <td>780</td>\n",
       "      <td>2</td>\n",
       "      <td>0.985916</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.560847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26604</th>\n",
       "      <td>8700</td>\n",
       "      <td>11</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.198113</td>\n",
       "      <td>589</td>\n",
       "      <td>750</td>\n",
       "      <td>111</td>\n",
       "      <td>912</td>\n",
       "      <td>858</td>\n",
       "      <td>356</td>\n",
       "      <td>7</td>\n",
       "      <td>0.957747</td>\n",
       "      <td>0.987000</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.502645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26605</th>\n",
       "      <td>8700</td>\n",
       "      <td>11</td>\n",
       "      <td>0.091837</td>\n",
       "      <td>0.717778</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>296</td>\n",
       "      <td>356</td>\n",
       "      <td>589</td>\n",
       "      <td>750</td>\n",
       "      <td>111</td>\n",
       "      <td>593</td>\n",
       "      <td>13</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.936777</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.449735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26606</th>\n",
       "      <td>8700</td>\n",
       "      <td>11</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.220126</td>\n",
       "      <td>110</td>\n",
       "      <td>593</td>\n",
       "      <td>296</td>\n",
       "      <td>356</td>\n",
       "      <td>589</td>\n",
       "      <td>527</td>\n",
       "      <td>11</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.753746</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.439153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26607</th>\n",
       "      <td>9592</td>\n",
       "      <td>7</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>0.764444</td>\n",
       "      <td>0.185535</td>\n",
       "      <td>168</td>\n",
       "      <td>500</td>\n",
       "      <td>39</td>\n",
       "      <td>902</td>\n",
       "      <td>231</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.057475</td>\n",
       "      <td>0.378472</td>\n",
       "      <td>0.608466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26608 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  userGenre1  scaleduserRatingCount  scaleduserAvgRating  \\\n",
       "0       10436           3               0.102041             0.888889   \n",
       "1       10436           7               0.244898             0.828889   \n",
       "2       11078           7               0.112245             0.684444   \n",
       "3       11078          12               0.153061             0.686667   \n",
       "4       11078          12               0.214286             0.686667   \n",
       "...       ...         ...                    ...                  ...   \n",
       "26603    7447           2               0.091837             0.697778   \n",
       "26604    8700          11               0.071429             0.680000   \n",
       "26605    8700          11               0.091837             0.717778   \n",
       "26606    8700          11               0.122449             0.722222   \n",
       "26607    9592           7               0.163265             0.764444   \n",
       "\n",
       "       scaleduserRatingStddev  userRatedMovie1  userRatedMovie2  \\\n",
       "0                    0.094340              356              593   \n",
       "1                    0.141509              104              750   \n",
       "2                    0.229560              608                1   \n",
       "3                    0.201258              922              628   \n",
       "4                    0.188679              377              588   \n",
       "...                       ...              ...              ...   \n",
       "26603                0.264151                1              589   \n",
       "26604                0.198113              589              750   \n",
       "26605                0.226415              296              356   \n",
       "26606                0.220126              110              593   \n",
       "26607                0.185535              168              500   \n",
       "\n",
       "       userRatedMovie3  userRatedMovie4  userRatedMovie5  movieId  \\\n",
       "0                  592              480              899      588   \n",
       "1                    2              586              141      368   \n",
       "2                  150              457              593       50   \n",
       "3                   47               50              608      527   \n",
       "4                  380              527              922      733   \n",
       "...                ...              ...              ...      ...   \n",
       "26603              260              110              593      780   \n",
       "26604              111              912              858      356   \n",
       "26605              589              750              111      593   \n",
       "26606              296              356              589      527   \n",
       "26607               39              902              231       12   \n",
       "\n",
       "       movieGenre1  scaledReleaseYear  scaledmovieRatingCount  \\\n",
       "0                3           0.929577                0.614369   \n",
       "1                3           0.957747                0.256928   \n",
       "2               13           0.971831                0.699282   \n",
       "3               11           0.943662                0.753746   \n",
       "4                2           0.985916                0.467739   \n",
       "...            ...                ...                     ...   \n",
       "26603            2           0.985916                0.702703   \n",
       "26604            7           0.957747                0.987000   \n",
       "26605           13           0.915493                0.936777   \n",
       "26606           11           0.943662                0.753746   \n",
       "26607            7           0.971831                0.057475   \n",
       "\n",
       "       scaledmovieAvgRating  scaledmovieRatingStddev  \n",
       "0                  0.729167                 0.486773  \n",
       "1                  0.631945                 0.470899  \n",
       "2                  0.965278                 0.396825  \n",
       "3                  0.947917                 0.439153  \n",
       "4                  0.722222                 0.486773  \n",
       "...                     ...                      ...  \n",
       "26603              0.625000                 0.560847  \n",
       "26604              0.854167                 0.502645  \n",
       "26605              0.906250                 0.449735  \n",
       "26606              0.947917                 0.439153  \n",
       "26607              0.378472                 0.608466  \n",
       "\n",
       "[26608 rows x 16 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> userId\n",
      "1 -> userGenre1\n",
      "2 -> scaleduserRatingCount\n",
      "3 -> scaleduserAvgRating\n",
      "4 -> scaleduserRatingStddev\n",
      "5 -> userRatedMovie1\n",
      "6 -> userRatedMovie2\n",
      "7 -> userRatedMovie3\n",
      "8 -> userRatedMovie4\n",
      "9 -> userRatedMovie5\n",
      "10 -> movieId\n",
      "11 -> movieGenre1\n",
      "12 -> scaledReleaseYear\n",
      "13 -> scaledmovieRatingCount\n",
      "14 -> scaledmovieAvgRating\n",
      "15 -> scaledmovieRatingStddev\n"
     ]
    }
   ],
   "source": [
    "for i, col_name in enumerate(training_feature.columns): # get column_index for each feature\n",
    "    print(str(i) + \" -> \" + col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_col = [0, 1, 11, 5, 6, 7, 8, 9, 10] # column_index of sparse features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_col_size = [30001, 20, 20, 1001, 1001, 1001, 1001, 1001, 1001] # number of classes per sparse_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_ratio = [3, 5, 1] # column_number of sparse column: behavior column: candidate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_col = [2, 3, 4, 12, 13, 14, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ModelDataSet(Dataset):\n",
    "    # Retrieve an item in every call\n",
    "    def __init__(self, input_DF, label_DF, sparse_col, dense_col):\n",
    "        self.df = input_DF\n",
    "        \n",
    "        self.dense_df = input_DF.iloc[:, dense_col].astype(np.float32) \n",
    "        self.sparse_df = input_DF.iloc[:, sparse_col].astype('int64') \n",
    "        \n",
    "        self.label = label_DF.astype(np.float32) \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        sparse_feature = torch.tensor(self.sparse_df.iloc[idx])\n",
    "        dense_feature = torch.tensor(self.dense_df.iloc[idx])\n",
    "        label = torch.tensor(self.label.iloc[idx])\n",
    "        return {'Feature': (sparse_feature, dense_feature), 'Label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_dataset = ModelDataSet(training_feature, training_label, sparse_col, dense_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ModelDataSet(test_feature, test_label, sparse_col, dense_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Feature': (tensor([10436,     3,     3,   356,   593,   592,   480,   899,   588]),\n",
       "  tensor([0.1020, 0.8889, 0.0943, 0.9296, 0.6144, 0.7292, 0.4868])),\n",
       " 'Label': tensor(1.)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define the Attention module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_ElementWiseProduct(nn.Module):\n",
    "    \"\"\"\n",
    "      Input:\n",
    "          behavior: 3D tensor with shape: ``(batch_size,field_size,embedding_size)``.\n",
    "          candidate: 3D tensor with shape: ``(batch_size,1,embedding_size)``.\n",
    "      Output:\n",
    "          attention_weight: 3D tensor with shape: ``(batch_size, field_size, 1)``.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_size):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(4*embedding_size, 32)\n",
    "        self.linear2 = nn.Linear(32, 1)\n",
    "        self.prelu = nn.PReLU()\n",
    "\n",
    "    def forward(self, behavior, candidate):\n",
    "        candidate = candidate.expand_as(behavior)\n",
    "        embed_input = torch.cat([behavior, candidate, behavior-candidate, behavior*candidate], dim=2)  # (B,F,4k)\n",
    "        output = self.prelu(self.linear1(embed_input))  # (B,F,32)\n",
    "        output = F.sigmoid(self.linear2(output)) # (B,F,1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class DIN(nn.Module):\n",
    "    def __init__(self, sparse_col_size, dense_col_size, sparse_ratio):\n",
    "        # sparse_col_size: list[int]\n",
    "        # dense_col_size: int\n",
    "        super().__init__()\n",
    "        self.sparse_col_size = sparse_col_size\n",
    "        self.dense_col_size = dense_col_size\n",
    "        self.sparse_ratio = sparse_ratio\n",
    "        \n",
    "        # For categorical features, we embed the features in dense vectors of dimension of 6 * category cardinality^1/4\n",
    "        embedding_size = list(map(lambda x: int(6 * pow(x, 0.25)), self.sparse_col_size))\n",
    "        \n",
    "        # Attention layer\n",
    "        movieId_embed_size = embedding_size[3]\n",
    "        self.attention_layer = Attention_ElementWiseProduct(movieId_embed_size)\n",
    "        \n",
    "        # Embedding layer for all sparse features\n",
    "        sparse_embedding_list = []\n",
    "        for class_size, embed_size in zip(self.sparse_col_size, embedding_size):\n",
    "            embed_layer = nn.Embedding(class_size, embed_size, scale_grad_by_freq=True)\n",
    "            # init embed_layer\n",
    "            # embed_layer.weight.data.uniform_(-1/math.sqrt(class_size), 1/math.sqrt(class_size))\n",
    "            sparse_embedding_list.append(embed_layer)\n",
    "        self.sparse_embedding_layer = nn.ModuleList(sparse_embedding_list)\n",
    "\n",
    "        # Deep layers\n",
    "        deep_input_size = np.sum(embedding_size) + dense_col_size - 4*movieId_embed_size\n",
    "        self.linear1 = nn.Linear(deep_input_size, 128)\n",
    "        self.prelu1 = nn.PReLU()\n",
    "        self.linear2 = nn.Linear(128, 64)\n",
    "        self.prelu2 = nn.PReLU()\n",
    "        self.linear3 = nn.Linear(64, 1)\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, sparse_feature, dense_feature):\n",
    "        if (len(sparse_feature.shape) == 1): # 1D tensor coverted to 2D tensor if batch_number == 1\n",
    "            sparse_feature = sparse_feature.view(1, -1)\n",
    "            dense_feature = dense_feature.view(1, -1)\n",
    "        \n",
    "        # convert sparse feature to oneHot and Embedding\n",
    "        embedding_list=[]\n",
    "        for i in range(len(self.sparse_col_size)):\n",
    "            sparse_feature_input = sparse_feature[:, i] # batch x 1\n",
    "            class_size = self.sparse_col_size[i]\n",
    "            embedding_layer = self.sparse_embedding_layer[i]\n",
    "            embedding_output = embedding_layer(sparse_feature_input).squeeze(1) # batch x embedding_size\n",
    "            embedding_list.append(embedding_output)\n",
    "            \n",
    "        # Split into \"other sparse feature\", behavior feature, candidate feature\n",
    "        sparse_embed_list = embedding_list[:self.sparse_ratio[0]]\n",
    "        behavior_embed_list = embedding_list[self.sparse_ratio[0]:self.sparse_ratio[0]+self.sparse_ratio[1]]\n",
    "        candidate = embedding_list[-1].unsqueeze(1)\n",
    "            \n",
    "        sparse_embedding = torch.cat(sparse_embed_list, dim=1)    \n",
    "        behavior = torch.stack(behavior_embed_list, dim=1)  # B x field_number x embedding_size\n",
    "        \n",
    "        # Cal the attention weight\n",
    "        attention_weight = self.attention_layer(behavior, candidate) # B x field_number x 1\n",
    "        \n",
    "        # Apply attention weight and do sumPooling\n",
    "        attention_behavior = attention_weight * behavior # B x field_number x embedding_size\n",
    "        sumPool_behavior = attention_behavior.sum(dim=1) # B x embedding_size\n",
    "        \n",
    "        deep_input = torch.cat([sparse_embedding, dense_feature, sumPool_behavior, candidate.squeeze()], dim=1)\n",
    "        \n",
    "        # Deep layer\n",
    "        deep_output = self.prelu1(self.linear1(deep_input))\n",
    "        deep_output = self.prelu2(self.linear2(deep_output))\n",
    "        deep_output = self.linear3(deep_output)\n",
    "        return F.sigmoid(deep_output).view(-1) # (B,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DIN(sparse_col_size, 7, sparse_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add weight decay for all parameters in the model other than those in PReLU layer\n",
    "para_list = []\n",
    "for para_name, para in model.named_parameters():\n",
    "    if 'prelu' in para_name:\n",
    "        para_list.append({'params': para, 'weight_decay':0})\n",
    "    else:\n",
    "        para_list.append({'params': para})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(para_list, lr=LR, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Eval():\n",
    "    def __init__(self, model, loss_fn, optim, device, train_dataloader, test_dataloader):\n",
    "        self.device = device\n",
    "        self.model = model.to(self.device)\n",
    "        self.optim = optim\n",
    "        self.loss_fn = loss_fn\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "        self.threashold = 0.5 # threashold for positive class\n",
    "        \n",
    "    def train(self, epochs):\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            print(\"==========================================================\")\n",
    "            print(\"start training epoch: {}\".format(epoch+1))\n",
    "            loss_list = []\n",
    "            pred_list = []\n",
    "            label_list = []\n",
    "            \n",
    "            iteration = 1\n",
    "            for train_data in self.train_dataloader:\n",
    "                sparse_feature = train_data['Feature'][0].to(self.device)\n",
    "                dense_feature = train_data['Feature'][1].to(self.device)\n",
    "                label = train_data['Label'].to(self.device)\n",
    "                prediction = self.model(sparse_feature, dense_feature)\n",
    "                \n",
    "                pred_list.extend(prediction.tolist())\n",
    "                label_list.extend(label.tolist())\n",
    "                \n",
    "                cur_loss = self.loss_fn(prediction, label)\n",
    "                loss_list.append(cur_loss.item())\n",
    "                cur_loss.backward()\n",
    "                self.optim.step()\n",
    "                self.optim.zero_grad()\n",
    "                \n",
    "                # logging every 20 iteration\n",
    "                if iteration % 20 == 0:\n",
    "                    print(\"---------------------------------------------------------\")\n",
    "                    print(\"epoch {}/{}, cur_iteration is {}, logloss is {:.2f}\"\n",
    "                          .format(epoch+1, epochs, iteration, cur_loss.item()))\n",
    "                iteration += 1\n",
    "                \n",
    "            # validation every epoch\n",
    "            training_loss, training_accuracy, training_roc_score = self._getMetric(loss_list, pred_list, label_list)\n",
    "            print(\"==========================================================\")\n",
    "            print(\"Result of epoch {}\".format(epoch+1))\n",
    "            print(f\"training loss: {training_loss:.2f}, accuracy: {training_accuracy:.3f}, roc_score: {training_roc_score:.2f}\")\n",
    "            \n",
    "            test_loss, test_accuracy, test_roc_score = self.eval()\n",
    "            print(f\"test loss: {test_loss:.2f}, accuracy: {test_accuracy:.3f}, roc_score: {test_roc_score:.2f}\")\n",
    "            # summary.add_embedding(np.reshape(np.array(loss_list), (1, -1)), tag=\"loss_list\")\n",
    "            # summary.add_embedding(np.reshape(np.array(pred_list), (1, -1)), tag=\"pred_list\")\n",
    "            # summary.add_embedding(np.reshape(np.array(label_list), (1, -1)), tag=\"label_list\")\n",
    "            # summary.add_scalar(\"training_loss\", training_loss)\n",
    "            # summary.add_scalar(\"training_accuracy\", training_accuracy)\n",
    "            # summary.add_scalar(\"training_roc_score\", training_roc_score)\n",
    "    \n",
    "    def eval(self):\n",
    "        # return logloss, accuracy, roc_score\n",
    "        self.model.eval()\n",
    "        loss_list = []\n",
    "        pred_list = []\n",
    "        label_list = []\n",
    "        with torch.no_grad():\n",
    "            for test_data in self.test_dataloader:\n",
    "                sparse_feature = test_data['Feature'][0].to(self.device)\n",
    "                dense_feature = test_data['Feature'][1].to(self.device)\n",
    "                label = test_data['Label'].to(self.device)\n",
    "                prediction = self.model(sparse_feature, dense_feature)\n",
    "                cur_loss = self.loss_fn(prediction, label)\n",
    "                \n",
    "                loss_list.append(cur_loss.item())\n",
    "                pred_list.extend(prediction.tolist())\n",
    "                label_list.extend(label.tolist())\n",
    "        return self._getMetric(loss_list, pred_list, label_list)\n",
    "                \n",
    "    def _getMetric(self, loss_list, pred_list, label_list):\n",
    "        # return logloss, accuracy, roc_score        \n",
    "        # average logloss\n",
    "        avg_loss = np.mean(loss_list)\n",
    "        # roc_score\n",
    "        roc_score = roc_auc_score(label_list, pred_list)\n",
    "        # average accuracy\n",
    "        pred_class_list = list(map(lambda x: 1 if x >= self.threashold else 0, pred_list))\n",
    "        correct_count = 0\n",
    "        for p, l in zip(pred_class_list, label_list):\n",
    "            if p == l:\n",
    "                correct_count += 1\n",
    "        avg_accuracy = correct_count / len(label_list)\n",
    "        \n",
    "        return avg_loss, avg_accuracy, roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval = Train_Eval(model, loss_fn, optimizer, dev, training_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "start training epoch: 1\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 20, logloss is 0.68\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 40, logloss is 0.68\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 60, logloss is 0.68\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 80, logloss is 0.65\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 100, logloss is 0.66\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 120, logloss is 0.66\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 140, logloss is 0.67\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 160, logloss is 0.63\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 180, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 200, logloss is 0.66\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 220, logloss is 0.65\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 240, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 260, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 280, logloss is 0.65\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 300, logloss is 0.63\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 320, logloss is 0.66\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 340, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 360, logloss is 0.66\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 380, logloss is 0.63\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 400, logloss is 0.63\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 420, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 440, logloss is 0.67\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 460, logloss is 0.68\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 480, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 500, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 520, logloss is 0.63\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 540, logloss is 0.69\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 560, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 580, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 600, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 620, logloss is 0.63\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 640, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 660, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 680, logloss is 0.63\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 700, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 720, logloss is 0.64\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 740, logloss is 0.68\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 760, logloss is 0.63\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 780, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 800, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 820, logloss is 0.70\n",
      "---------------------------------------------------------\n",
      "epoch 1/5, cur_iteration is 840, logloss is 0.55\n",
      "==========================================================\n",
      "Result of epoch 1\n",
      "training loss: 0.63, accuracy: 0.642, roc_score: 0.70\n",
      "test loss: 0.56, accuracy: 0.715, roc_score: 0.76\n",
      "==========================================================\n",
      "start training epoch: 2\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 20, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 40, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 60, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 80, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 100, logloss is 0.63\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 120, logloss is 0.63\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 140, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 160, logloss is 0.64\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 180, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 200, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 220, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 240, logloss is 0.64\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 260, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 280, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 300, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 320, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 340, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 360, logloss is 0.63\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 380, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 400, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 420, logloss is 0.63\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 440, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 460, logloss is 0.65\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 480, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 500, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 520, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 540, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 560, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 580, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 600, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 620, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 640, logloss is 0.56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 660, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 680, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 700, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 720, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 740, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 760, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 780, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 800, logloss is 0.51\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 820, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 2/5, cur_iteration is 840, logloss is 0.58\n",
      "==========================================================\n",
      "Result of epoch 2\n",
      "training loss: 0.59, accuracy: 0.689, roc_score: 0.75\n",
      "test loss: 0.55, accuracy: 0.725, roc_score: 0.78\n",
      "==========================================================\n",
      "start training epoch: 3\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 20, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 40, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 60, logloss is 0.63\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 80, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 100, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 120, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 140, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 160, logloss is 0.50\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 180, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 200, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 220, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 240, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 260, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 280, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 300, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 320, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 340, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 360, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 380, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 400, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 420, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 440, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 460, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 480, logloss is 0.50\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 500, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 520, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 540, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 560, logloss is 0.51\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 580, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 600, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 620, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 640, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 660, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 680, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 700, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 720, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 740, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 760, logloss is 0.66\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 780, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 800, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 820, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 3/5, cur_iteration is 840, logloss is 0.63\n",
      "==========================================================\n",
      "Result of epoch 3\n",
      "training loss: 0.57, accuracy: 0.700, roc_score: 0.77\n",
      "test loss: 0.53, accuracy: 0.741, roc_score: 0.79\n",
      "==========================================================\n",
      "start training epoch: 4\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 20, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 40, logloss is 0.50\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 60, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 80, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 100, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 120, logloss is 0.51\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 140, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 160, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 180, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 200, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 220, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 240, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 260, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 280, logloss is 0.48\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 300, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 320, logloss is 0.50\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 340, logloss is 0.45\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 360, logloss is 0.64\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 380, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 400, logloss is 0.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 420, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 440, logloss is 0.65\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 460, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 480, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 500, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 520, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 540, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 560, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 580, logloss is 0.48\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 600, logloss is 0.50\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 620, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 640, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 660, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 680, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 700, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 720, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 740, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 760, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 780, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 800, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 820, logloss is 0.51\n",
      "---------------------------------------------------------\n",
      "epoch 4/5, cur_iteration is 840, logloss is 0.60\n",
      "==========================================================\n",
      "Result of epoch 4\n",
      "training loss: 0.57, accuracy: 0.705, roc_score: 0.77\n",
      "test loss: 0.54, accuracy: 0.736, roc_score: 0.79\n",
      "==========================================================\n",
      "start training epoch: 5\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 20, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 40, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 60, logloss is 0.50\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 80, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 100, logloss is 0.60\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 120, logloss is 0.61\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 140, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 160, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 180, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 200, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 220, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 240, logloss is 0.48\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 260, logloss is 0.64\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 280, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 300, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 320, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 340, logloss is 0.65\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 360, logloss is 0.63\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 380, logloss is 0.63\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 400, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 420, logloss is 0.63\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 440, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 460, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 480, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 500, logloss is 0.65\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 520, logloss is 0.54\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 540, logloss is 0.62\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 560, logloss is 0.55\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 580, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 600, logloss is 0.70\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 620, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 640, logloss is 0.65\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 660, logloss is 0.52\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 680, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 700, logloss is 0.53\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 720, logloss is 0.64\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 740, logloss is 0.56\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 760, logloss is 0.57\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 780, logloss is 0.49\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 800, logloss is 0.59\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 820, logloss is 0.58\n",
      "---------------------------------------------------------\n",
      "epoch 5/5, cur_iteration is 840, logloss is 0.56\n",
      "==========================================================\n",
      "Result of epoch 5\n",
      "training loss: 0.56, accuracy: 0.708, roc_score: 0.78\n"
     ]
    }
   ],
   "source": [
    "train_eval.train(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
